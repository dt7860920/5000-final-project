{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14f18ced",
   "metadata": {},
   "source": [
    "# Data Collection from PGA Website\n",
    "This file is used to scrape data from PGA official website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8e7436a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5e77b979",
   "metadata": {},
   "outputs": [],
   "source": [
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) \"\n",
    "                  \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                  \"Chrome/120.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "def scrape_espn_player_stats(season: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Scrape ESPN 'PGA TOUR Player Stats {season}' page.\n",
    "\n",
    "    Returns a DataFrame with:\n",
    "    NAME, Season, EARNINGS, CUP, EVNTS, RNDS, CUTS, TOP10, WINS,\n",
    "    SCORE, DDIS, DACC, GIR, PUTTS, SAND, BIRDS\n",
    "    \"\"\"\n",
    "    url = f\"https://www.espn.com/golf/stats/player/_/season/{season}\"\n",
    "    print(f\"Scraping {season} from {url}\")\n",
    "\n",
    "    resp = requests.get(url, headers=HEADERS)\n",
    "    resp.raise_for_status()\n",
    "\n",
    "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "\n",
    "    # ---------- 1) Get raw text lines ----------\n",
    "    text = soup.get_text(\"\\n\")\n",
    "    lines = [ln.strip() for ln in text.splitlines() if ln.strip()]\n",
    "\n",
    "    # This header line appears right before the stat rows.\n",
    "    # In the flattened text it looks like this (no spaces):\n",
    "    # EARNINGSCUPEVNTSRNDSCUTSTOP10WINSSCOREDDISDACCGIRPUTTSSANDBIRDS\n",
    "    header_compact = \"EARNINGSCUPEVNTSRNDSCUTSTOP10WINSSCOREDDISDACCGIRPUTTSSANDBIRDS\"\n",
    "\n",
    "    stats_start = None\n",
    "    for i, ln in enumerate(lines):\n",
    "        if ln.replace(\" \", \"\") == header_compact:\n",
    "            stats_start = i + 1  # stats start on next line\n",
    "            break\n",
    "\n",
    "    if stats_start is None:\n",
    "        raise ValueError(f\"Could not find stats header for season {season}.\")\n",
    "\n",
    "    # ---------- 2) Collect stats lines ----------\n",
    "    stat_lines = []\n",
    "    for ln in lines[stats_start:]:\n",
    "        if ln.startswith(\"Show More\"):\n",
    "            break  # end of table\n",
    "        if not ln.startswith(\"$\"):\n",
    "            continue  # skip non-stat lines\n",
    "        tokens = ln.split()\n",
    "        # Should be: $EARNINGS CUP EVNTS RNDS CUTS TOP10 WINS SCORE DDIS DACC GIR PUTTS SAND BIRDS\n",
    "        if len(tokens) != 14:\n",
    "            continue\n",
    "        stat_lines.append(tokens)\n",
    "\n",
    "    if not stat_lines:\n",
    "        raise ValueError(f\"No stat rows found for season {season}.\")\n",
    "\n",
    "    # ---------- 3) Collect player names ----------\n",
    "    # Player links have URLs like /golf/player/_/id/3599/brian-stuard\n",
    "    player_links = soup.find_all(\"a\", href=re.compile(r\"/golf/player/_/id/\"))\n",
    "    names = []\n",
    "    for a in player_links:\n",
    "        name = a.get_text(strip=True)\n",
    "        if name and name not in names:\n",
    "            names.append(name)\n",
    "\n",
    "    # We only have stats for the first N players; align lengths just in case\n",
    "    n = min(len(names), len(stat_lines))\n",
    "    names = names[:n]\n",
    "    stat_lines = stat_lines[:n]\n",
    "\n",
    "    # ---------- 4) Build DataFrame ----------\n",
    "    stat_cols = [\n",
    "        \"EARNINGS\", \"CUP\", \"EVNTS\", \"RNDS\", \"CUTS\", \"TOP10\", \"WINS\",\n",
    "        \"SCORE\", \"DDIS\", \"DACC\", \"GIR\", \"PUTTS\", \"SAND\", \"BIRDS\"\n",
    "    ]\n",
    "\n",
    "    records = []\n",
    "    for name, row in zip(names, stat_lines):\n",
    "        rec = {\n",
    "            \"NAME\": name,\n",
    "            \"Season\": season,\n",
    "        }\n",
    "        rec[\"EARNINGS\"] = row[0]    # '$x,xxx'\n",
    "        # map remaining 13 stats\n",
    "        for col, val in zip(stat_cols[1:], row[1:]):\n",
    "            rec[col] = val\n",
    "        records.append(rec)\n",
    "\n",
    "    df = pd.DataFrame.from_records(records)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1a03c43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_espn_range(start_season: int, end_season: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Scrape multiple seasons from ESPN and stack into one DataFrame.\n",
    "    \"\"\"\n",
    "    all_frames = []\n",
    "    for season in range(start_season, end_season + 1):\n",
    "        try:\n",
    "            df_season = scrape_espn_player_stats(season)\n",
    "            all_frames.append(df_season)\n",
    "        except Exception as e:\n",
    "            print(f\"Season {season} failed: {e}\")\n",
    "\n",
    "    if not all_frames:\n",
    "        raise RuntimeError(\"No seasons were successfully scraped.\")\n",
    "\n",
    "    combined = pd.concat(all_frames, ignore_index=True)\n",
    "    return combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b2e0ba0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping 2019 from https://www.espn.com/golf/stats/player/_/season/2019\n",
      "Season 2019 failed: Could not find stats header for season 2019.\n",
      "Scraping 2020 from https://www.espn.com/golf/stats/player/_/season/2020\n",
      "Season 2020 failed: Could not find stats header for season 2020.\n",
      "Scraping 2021 from https://www.espn.com/golf/stats/player/_/season/2021\n",
      "Season 2021 failed: Could not find stats header for season 2021.\n",
      "Scraping 2022 from https://www.espn.com/golf/stats/player/_/season/2022\n",
      "Season 2022 failed: Could not find stats header for season 2022.\n",
      "Scraping 2023 from https://www.espn.com/golf/stats/player/_/season/2023\n",
      "Season 2023 failed: Could not find stats header for season 2023.\n",
      "Scraping 2024 from https://www.espn.com/golf/stats/player/_/season/2024\n",
      "Season 2024 failed: Could not find stats header for season 2024.\n",
      "Scraping 2025 from https://www.espn.com/golf/stats/player/_/season/2025\n",
      "Season 2025 failed: Could not find stats header for season 2025.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No seasons were successfully scraped.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m espn_recent = \u001b[43mscrape_espn_range\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m2019\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2025\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Save to your project raw-data folder\u001b[39;00m\n\u001b[32m      4\u001b[39m espn_recent.to_csv(\u001b[33m\"\u001b[39m\u001b[33mdata/raw-data/espn_pga_stats_2019_2025_top_players.csv\u001b[39m\u001b[33m\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mscrape_espn_range\u001b[39m\u001b[34m(start_season, end_season)\u001b[39m\n\u001b[32m     11\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSeason \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseason\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m failed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m all_frames:\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo seasons were successfully scraped.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     16\u001b[39m combined = pd.concat(all_frames, ignore_index=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m combined\n",
      "\u001b[31mRuntimeError\u001b[39m: No seasons were successfully scraped."
     ]
    }
   ],
   "source": [
    "espn_recent = scrape_espn_range(2019, 2025)\n",
    "\n",
    "# Save to your project raw-data folder\n",
    "espn_recent.to_csv(\"data/raw-data/espn_pga_stats_2019_2025_top_players.csv\", index=False)\n",
    "\n",
    "espn_recent.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
