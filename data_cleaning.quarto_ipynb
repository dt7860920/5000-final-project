{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Data Cleaning\"\n",
        "format:\n",
        "  html:\n",
        "    toc: true\n",
        "    code-fold: true\n",
        "    embed-resources: true\n",
        "execute:\n",
        "  echo: true\n",
        "  warning: false\n",
        "  message: false\n",
        "---\n",
        "\n",
        "### Data Cleaning\n",
        "Load Data: This step establishes the two primary data sources that will later be merged into a unified dataset for analysis."
      ],
      "id": "fa066503"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "raw_path = \"data/raw-data/pgatour_raw.csv\"\n",
        "full_path = \"data/raw-data/pga_full.csv\"\n",
        "\n",
        "df_raw = pd.read_csv(raw_path, encoding=\"latin1\")\n",
        "df_full = pd.read_csv(full_path, encoding=\"latin1\")"
      ],
      "id": "6a056094",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Helper Function\n",
        "Before cleaning the data, I define several helper functions designed to standardize formatting across both datasets.\n",
        "\n",
        "**Clean column names: **\n",
        "\n",
        "* Converts names to lowercase\n",
        "\n",
        "* Replaces spaces with underscores\n",
        "\n",
        "* Removes stray punctuation\n",
        "\n",
        "* Standardizes percent signs (%)\n",
        "\n",
        "\n",
        "**Clean numeric data: **\n",
        "\n",
        "* Commas\n",
        "\n",
        "* Dollar signs\n",
        "\n",
        "* Percentage symbols\n",
        "\n",
        "**Clean player name: **\n",
        "\n",
        "* Extra spaces\n",
        "\n",
        "* Commas\n",
        "\n",
        "* Inconsistent capitalization"
      ],
      "id": "18096f47"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def clean_column_names(df):\n",
        "    df = df.copy()\n",
        "    df.columns = (\n",
        "        df.columns\n",
        "        .str.strip()\n",
        "        .str.lower()\n",
        "        .str.replace(\" \", \"_\")\n",
        "        .str.replace(\"%\", \"pct\")\n",
        "        .str.replace(\".\", \"_\")\n",
        "    )\n",
        "    return df\n",
        "\n",
        "def clean_numeric(series):\n",
        "    return (\n",
        "        series.astype(str)\n",
        "        .str.replace(\",\", \"\", regex=False)\n",
        "        .str.replace(\"$\", \"\", regex=False)\n",
        "        .str.replace(\"%\", \"\", regex=False)\n",
        "        .replace(\"\", np.nan)\n",
        "        .astype(float)\n",
        "    )\n",
        "\n",
        "def clean_player_name(name):\n",
        "    name = str(name)\n",
        "    name = name.replace(\",\", \"\").strip()\n",
        "    return name.title()"
      ],
      "id": "5f5e8458",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Standardize Player Names\n",
        "I apply the name-cleaning function to both datasets, so names can be recignized during the merging process."
      ],
      "id": "0f9f47db"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "if \"name\" in df_raw.columns:\n",
        "    df_raw[\"name\"] = df_raw[\"name\"].apply(clean_player_name)\n",
        "if \"name\" in df_full.columns:\n",
        "    df_full[\"name\"] = df_full[\"name\"].apply(clean_player_name)"
      ],
      "id": "f5aa195c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fix Numeric Columns\n",
        "I apply the clean_numeric function to standardize all the columns with numeric data"
      ],
      "id": "805726f4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "numeric_raw = [\n",
        "    \"rounds\", \"scoring\", \"drive_distance\",\n",
        "    \"gir_pct\", \"sg_p\", \"sg_ttg\", \"sg_t\",\n",
        "    \"top_10\", \"win\"\n",
        "]\n",
        "numeric_full = [\n",
        "    \"rounds\", \"scoring\", \"birdie_avg\", \"drive_distance\",\n",
        "    \"gir_pct\", \"sg_p\", \"sg_ttg\", \"sg_t\",\n",
        "    \"top_10\", \"win\"\n",
        "]\n",
        "\n",
        "for col in numeric_raw:\n",
        "    if col in df_raw.columns:\n",
        "        df_raw[col] = clean_numeric(df_raw[col])\n",
        "\n",
        "for col in numeric_full:\n",
        "    if col in df_full.columns:\n",
        "        df_full[col] = clean_numeric(df_full[col])\n",
        "\n",
        "# Year should be numeric\n",
        "for df in [df_raw, df_full]:\n",
        "    if \"year\" in df.columns:\n",
        "        df[\"year\"] = pd.to_numeric(df[\"year\"], errors=\"coerce\").astype(\"Int64\")"
      ],
      "id": "cfcf7965",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Standardize Column Names\n",
        "I standardized all the column names for both datasets, making the merge process much easier."
      ],
      "id": "b0e282d1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_raw = clean_column_names(df_raw)\n",
        "df_full = clean_column_names(df_full)\n",
        "\n",
        "df_full = df_full.rename(columns={\n",
        "    \"player\": \"name\",\n",
        "    \"scoringavg\": \"scoring\",\n",
        "    \"birdieavg\": \"birdie_avg\",\n",
        "    \"drivingdistance\": \"drive_distance\",\n",
        "    \"gir\": \"gir_pct\",\n",
        "    \"girpct\": \"gir_pct\",\n",
        "    \"sg_putting\": \"sg_p\",\n",
        "    \"sg_total\": \"sg_t\",\n",
        "    \"sg_teetogreen\": \"sg_ttg\",\n",
        "    \"top10finishes\": \"top_10\",\n",
        "    \"wins\": \"win\"\n",
        "})\n",
        "\n",
        "# ---- pgatour_raw.csv ----\n",
        "df_raw = df_raw.rename(columns={\n",
        "    \"top_10\": \"top_10\",\n",
        "    \"1st\": \"win\",\n",
        "    \"1_st\": \"win\",\n",
        "    \"1st_\": \"win\",\n",
        "    \"gir__pct\": \"gir_pct\",   # depending on how the % got mapped\n",
        "    \"gir_pct\": \"gir_pct\",\n",
        "    \"fwy__pct\": \"fwy_pct\",\n",
        "    \"fwy_pct\": \"fwy_pct\"\n",
        "})"
      ],
      "id": "afcda6ef",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Select Overlapping Features in both Dataset\n",
        "* Select the wanted columns\n",
        "* Drop all the overlapping features"
      ],
      "id": "6cdf1572"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "standard_cols = [\n",
        "    \"name\", \"year\", \"country\",\n",
        "    \"scoring\",\n",
        "    \"drive_distance\", \"gir_pct\",\n",
        "    \"sg_p\", \"sg_ttg\", \"sg_t\",\n",
        "    \"top_10\", \"win\"\n",
        "]\n",
        "\n",
        "for col in standard_cols:\n",
        "    if col not in df_raw.columns:\n",
        "        df_raw[col] = pd.NA\n",
        "    if col not in df_full.columns:\n",
        "        df_full[col] = pd.NA\n",
        "\n",
        "df_raw_std = df_raw[standard_cols]\n",
        "df_full_std = df_full[standard_cols]"
      ],
      "id": "5c467ae3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Merging\n",
        "Merge both datasets into one uniformed dataframe.\n",
        "Problem: I realized that the players who did not win or get top 10 have null in their column instead of one. This will cause en error during the analysis process, so I replaced all the null with 0.\n",
        "Then I dropped duplicate players and keep the one with less missing data."
      ],
      "id": "f092125d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "combined = pd.concat([df_raw_std, df_full_std], ignore_index=True)\n",
        "\n",
        "combined[\"win\"] = combined[\"win\"].fillna(0).astype(\"Int64\")\n",
        "combined[\"top_10\"] = combined[\"top_10\"].fillna(0).astype(\"Int64\")\n",
        "\n",
        "combined[\"non_na_count\"] = combined.notna().sum(axis=1)\n",
        "\n",
        "combined = (\n",
        "    combined.sort_values([\"name\", \"year\", \"non_na_count\"])\n",
        "            .drop_duplicates(subset=[\"name\", \"year\"], keep=\"last\")\n",
        "            .drop(columns=\"non_na_count\")\n",
        ")\n",
        "\n",
        "print(\"Final shape:\", combined.shape)\n",
        "print(combined.head())"
      ],
      "id": "fefbbad0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Merged Data"
      ],
      "id": "41665090"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "output_path = \"data/processed-data/pga_cleaned.csv\"\n",
        "combined.to_csv(output_path, index=False)\n",
        "output_path"
      ],
      "id": "eb8d31f3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Before & After Comparison\n",
        "Confirm the transformation"
      ],
      "id": "b8535684"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_raw.head()\n",
        "df_full.head()\n",
        "combined.head()"
      ],
      "id": "e7e33f6d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Limitations on data cleaning:\n",
        "* Replacing missing wins and top 10s with zero can introduce bias\n",
        "* Removing characters like % and $ in the numeric columns may loses context\n",
        "* Missing data imputation was not used, leaving missing stats as NaN\n"
      ],
      "id": "c66e0792"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "base",
      "language": "python",
      "display_name": "Python (base)",
      "path": "/Users/Daniel/Library/Jupyter/kernels/base"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}